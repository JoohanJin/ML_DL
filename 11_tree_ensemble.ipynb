{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Ensemble\n",
    "##### Ensemble Learning (앙상블 학습)\n",
    "- Based on decision tree\n",
    "- best machine learning algorithm to deal with structured data\n",
    "\n",
    "##### Random Forest\n",
    "- Randomly make decision tree and make the forest of a number of decision trees.\n",
    "- Make a use of prediction from each Decition Tree and construct a final prediction\n",
    "\n",
    "**Bootstrap Sample**\n",
    "- In data set, 중복을 허용하여 데이터를 sampling, allowing repetition\n",
    "    - Bootstrap Sample: Sample made by Bootstrap method\n",
    "- 1,000 개의 샘플이 들어있는 가방에서 100개의 샘플을 뽑는다면 먼저 한 개를 뽑고, 뽑았던 것을 다시 가방에 넣는다.\n",
    "- 이런 식으로 100개를 뽑으면 중복된 샘플을 뽑을 수 있음 -> 이게 Bootstrap Sample, 부트스트랩 샘플\n",
    "- usually the size of bootstrap sample is equal to the size of train set\n",
    "    - 1,000 samples -> 1,000 bootstrap samples\n",
    "- Train Set -> random smaple by bootstrap sampling -> decision tree training\n",
    "    -> will make a lot of trees, and eventually construct a forest\n",
    "\n",
    "\n",
    "\n",
    "\\\n",
    "**In Scikit learn**\n",
    "- `RandomForestClassifier`\n",
    "    - 전체 특성 개수의 square root만큼의 feature을 선택\n",
    "        - e.g. 4 features -> each node will randomly choose 2 features and use it to decide the best split for each node\n",
    "    - Train 100 decision trees using the method specified above\n",
    "        - If classification\n",
    "            - 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측\n",
    "        - If regression\n",
    "            - 단순히 각 트리의 예측을 평균\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Tree (엑스트라 트리)\n",
    "- similar to random forest\n",
    "- default tree number = 100\n",
    "- 전체 특성 중에 일부 특성을 랜덤하게 선택하여 노드를 분할하는 데에 사용\n",
    "    - 성능은 낮지만\n",
    "    - 많은 트리를 만들기엔 적합\n",
    "- not using Bootstrap Sample\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "- 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블\n",
    "\n",
    "##### in Scikit Learn\n",
    "- `GradientBoostingClassifier`\n",
    "    - default depth = 3\n",
    "    - 높은 일반화 성능 & useful to prevent overfitting\n",
    "- stochastic gradient descent is used to add trees into Ensemble\n",
    "- For Classification\n",
    "    - logistic loss function is used\n",
    "- For Regression\n",
    "    - average square loss function is used\n",
    "- Parameter: `subsample`\n",
    "    - default value is 1 -> use the entire train set for training\n",
    "    - less than 1 -> part of train set for taining. -> similar to stochastic gradient descent and mini-batch gradient descent\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram-Based Gradient Boosting\n",
    "- split features into 256 parts\n",
    "    - can be used to find the most optimal split very fast\n",
    "    - one part is used for exceptioal feature\n",
    "\n",
    "##### in Scikitlearn\n",
    "- `HistGradientBoostingClassifier`\n",
    "    - stable performance\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of Data\n",
    "##### Structured Data (정형 데이터)\n",
    "- easy to store in DB, EXCEL or CSV\n",
    "- Best to be deailt by Ensemble Learning\n",
    "\n",
    "\n",
    "##### Unstructured Data (비정형 데이터)\n",
    "- hard to store in EXCEL, CSV\n",
    "- NLP will deal with it (신경망 알고리즘)\n",
    "- e.g.,\n",
    "    - music\n",
    "    - text\n",
    "    - etc.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  sugar    pH  class\n",
       "0      9.4    1.9  3.51    0.0\n",
       "1      9.8    2.6  3.20    0.0\n",
       "2      9.8    2.3  3.26    0.0\n",
       "3      9.8    1.9  3.16    0.0\n",
       "4      9.4    1.9  3.51    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# declare RandomForestClassifer\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100, # the number of trees constructing ensemble, default value is 100\n",
    "    n_jobs=-1, # use all of the cores\n",
    "    random_state=42, # should be commented in the real-life\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross_validate for RandomForestClassifier\n",
    "scores = cross_validate(\n",
    "    rf,\n",
    "    train_input,\n",
    "    train_target,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "# Overfitted\n",
    "print(\n",
    "    np.mean(scores.get(\"train_score\")),\n",
    "    np.mean(scores.get(\"test_score\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23167441 0.50039841 0.26792718]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_) # alcohol, sugar, pH\n",
    "print(rf.n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934000384837406\n"
     ]
    }
   ],
   "source": [
    "# OOB: out of bag sample, which has not been selected during bootstrap selection\n",
    "rf = RandomForestClassifier(\n",
    "    oob_score=True,\n",
    "    n_jobs=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(train_input, train_target)\n",
    "\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier(\n",
    "    n_jobs = -1,\n",
    "    random_state=42, # commented in real-life\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    et,\n",
    "    train_input,\n",
    "    train_target,\n",
    "    return_train_score=True,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores[\"train_score\"]), np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20183568 0.52242907 0.27573525]\n"
     ]
    }
   ],
   "source": [
    "et.fit(train_input, train_target)\n",
    "print(et.feature_importances_) # Alcohol, Sugar, pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrssion version: ExtraTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scores = cross_validate(\n",
    "    gb,\n",
    "    train_input,\n",
    "    train_target,\n",
    "    return_train_score= True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # Oh yeah, not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464595437171814 0.8780082549788999\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scores = cross_validate(\n",
    "    gb,\n",
    "    train_input,\n",
    "    train_target,\n",
    "    return_train_score=True,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15887763 0.6799705  0.16115187]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogram-Based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scores = cross_validate(\n",
    "    hgb,\n",
    "    train_input,\n",
    "    train_target,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08876275 0.23438522 0.08027708]\n"
     ]
    }
   ],
   "source": [
    "# to calcualte the feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "hgb.fit(train_input, train_target)\n",
    "result = permutation_importance(\n",
    "    hgb,\n",
    "    train_input,\n",
    "    train_target,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05969231 0.20238462 0.049     ]\n"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(\n",
    "    hgb,\n",
    "    test_input,\n",
    "    test_target,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723076923076923"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb.score(\n",
    "    test_input,\n",
    "    test_target\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
